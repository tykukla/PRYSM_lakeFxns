{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "#\n",
    "# --- generate sensitivity batch.csv file for CP\n",
    "# \n",
    "# -------------------------------------------------\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import qmc\n",
    "import warnings\n",
    "\n",
    "# --- where to save the batch file\n",
    "SAVE_ON = True\n",
    "savehere = \"/Users/tylerkukla/Documents/GitHub/PRYSM/psm/lake_v2/batch_inputs\"\n",
    "savename = \"batch_CP_sensitivity_climvars.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- create the parameter dict\n",
    "parameter_clim_inputs = {\n",
    "    \"datafile\": [\"sensitivityRun_modernTopo_280ppm+FLDS_lowTopo_500ppm_input.txt\", \n",
    "                 \"sensitivityRun_modernTopo_280ppm+FSDS_lowTopo_500ppm_input.txt\",\n",
    "                 \"sensitivityRun_modernTopo_280ppm+PRECT_lowTopo_500ppm_input.txt\",\n",
    "                 \"sensitivityRun_modernTopo_280ppm+PS_lowTopo_500ppm_input.txt\",\n",
    "                 \"sensitivityRun_modernTopo_280ppm+QFLX_lowTopo_500ppm_input.txt\",\n",
    "                 \"sensitivityRun_modernTopo_280ppm+RELHUM_lowTopo_500ppm_input.txt\",\n",
    "                 \"sensitivityRun_modernTopo_280ppm+TREFHT_lowTopo_500ppm_input.txt\",\n",
    "                 \"sensitivityRun_modernTopo_280ppm+U10_lowTopo_500ppm_input.txt\",\n",
    "                 ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- functions ---------------------------------\n",
    "# --- function to sample parameter space with latin hypercube\n",
    "def latin_hypercube_sampler(\n",
    "        parameter_ranges: dict,\n",
    "        n_samples: int,\n",
    "        nonnum_repeat_type: str,\n",
    "        round_to: int=2,\n",
    ")-> pd.DataFrame:\n",
    "    '''\n",
    "    Read in a dictionary of parameter ranges where each key is the parameter\n",
    "    name (as listed in defaults/default_dicts.py) and each value is a \n",
    "    list (e.g., `[0,1]`). Given a number of samples, return parameter values \n",
    "    for each sample. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter_ranges : dict\n",
    "        dictionary with keys equal to default_dicts.py parameters \n",
    "        (must be numeric!) and values indicating a min / max range.\n",
    "    n_samples : int\n",
    "        number of samples to generate (each sample amounts to a given\n",
    "        simulation of the PSM)\n",
    "    nonnum_repeat_type : str\n",
    "        [\"prescribed_cases\" | \"all_combinations\"] how to repeat the numeric \n",
    "        latin hypercube samples across the non-numeric parameters. \"prescribed_cases\"\n",
    "        means we repeat the lhs once for each index in the non-numeric params. \n",
    "        \"all_combinations\" means we repeat the lhs once for every possible \n",
    "        combination of the non-numeric params. \n",
    "    round_to : int\n",
    "        number of decimal places to round to. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame \n",
    "        dataframe where each column is a parameter and each row is a sample\n",
    "    '''\n",
    "    # separate numeric and non-numeric elements\n",
    "    numeric_params = {key: value for key, value in parameter_ranges.items() if all(isinstance(x, (int, float)) for x in value)}\n",
    "    non_numeric_params = {key: value for key, value in parameter_ranges.items() if not all(isinstance(x, (int, float)) for x in value)}\n",
    "\n",
    "    # -----\n",
    "    # make sure each value has only two elements\n",
    "    for key, values in numeric_params.items():\n",
    "        if len(values) != 2:\n",
    "            raise ValueError(f\"The key '{key}' has a length of {len(values)}, but it must be 2.\")\n",
    "    # -----\n",
    "    # get the number of parameters\n",
    "    num_parameters = len(numeric_params)\n",
    "\n",
    "    # create a latin hypercube sampler\n",
    "    sampler = qmc.LatinHypercube(d=num_parameters)\n",
    "\n",
    "    # generate the samples in the unit hypercube\n",
    "    sample = sampler.random(n=n_samples)\n",
    "    \n",
    "    # extract the ranges from the dictionary\n",
    "    keys = list(numeric_params.keys())\n",
    "    min_vals = [numeric_params[key][0] for key in keys]\n",
    "    max_vals = [numeric_params[key][1] for key in keys]\n",
    "\n",
    "    # scale the samples to the desired parameter ranges\n",
    "    scaled_sample = qmc.scale(sample, min_vals, max_vals)\n",
    "\n",
    "    # convert back to a dict\n",
    "    parameter_values = {keys[i]: np.round(scaled_sample[:, i], round_to) for i in range(num_parameters)}\n",
    "    # and now to a pandas dataframe\n",
    "    df_num = pd.DataFrame(parameter_values)\n",
    "\n",
    "    # --- handle the non-numeric values\n",
    "    if len(non_numeric_params) > 0:\n",
    "        if nonnum_repeat_type == \"prescribed_cases\": \n",
    "            df_nonnum = pd.DataFrame(non_numeric_params)\n",
    "        elif nonnum_repeat_type == \"all_combinations\":\n",
    "            # generate all combinations of parameter values\n",
    "            combinations = list(itertools.product(*non_numeric_params.values()))\n",
    "            df_nonnum = pd.DataFrame(combinations, columns=non_numeric_params.keys())\n",
    "        # merge dfs\n",
    "        # create a dummy key for cross join\n",
    "        df_num['key'] = 1\n",
    "        df_nonnum['key'] = 1\n",
    "        # merge the DataFrames on the dummy key\n",
    "        dfout = pd.merge(df_num, df_nonnum, on='key').drop('key', axis=1)\n",
    "    else:\n",
    "        dfout = df_num\n",
    "\n",
    "    # return result\n",
    "    return dfout\n",
    "\n",
    "\n",
    "# --- function to sample all possible values\n",
    "def all_combinations_sampler(\n",
    "        parameter_values: dict,\n",
    ")-> pd.DataFrame:\n",
    "    '''\n",
    "    Read in a dictionary of parameter values where each key is the parameter\n",
    "    name (as listed in defaults/default_dicts.py) and each value is a \n",
    "    list of values to test. Output a pd.DataFrame that includes all \n",
    "    possible combinations of the listed parameter values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter_ranges : dict\n",
    "        dictionary with keys equal to default_dicts.py parameters \n",
    "        (must be numeric!) and values are values to test.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame \n",
    "        dataframe where each column is a parameter and each row is a sample\n",
    "    '''\n",
    "    # check if all parameter value lengths are 2 (this might\n",
    "    # indicate that the dict is for latin hypercube sampling)\n",
    "    all_len_2 = all(len(value) == 2 for value in parameter_values.values())\n",
    "    if all_len_2:\n",
    "        warnings.warn(\"All lists in the dict have a length of 2. If these are min / max values, you may have meant to use the Latin hypercube sampler!\", UserWarning)\n",
    "\n",
    "    # generate all combinations of parameter values\n",
    "    combinations = list(itertools.product(*parameter_values.values()))\n",
    "\n",
    "    # create a DataFrame with parameter names as columns\n",
    "    df = pd.DataFrame(combinations, columns=parameter_values.keys())\n",
    "    # return result\n",
    "    return df\n",
    "\n",
    "# --- prescribed cases\n",
    "def prescribed_cases(\n",
    "        parameter_cases: dict,\n",
    ")->pd.DataFrame:\n",
    "    '''\n",
    "    Create pandas dataframe where each row is an individual experimental\n",
    "    setup that aligns 1:1 with the structure of the parameter_cases\n",
    "    dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter_cases : dict\n",
    "        dictionary with keys equal to default_dicts.py parameters \n",
    "        (must be numeric!) and values are values to test. Each \n",
    "        parameter value array must be the same length. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame \n",
    "        dataframe where each column is a parameter and each row is a sample\n",
    "    '''\n",
    "    # confirm that all lists are the same length\n",
    "    all_same_length = all(len(value) == len(next(iter(parameter_cases.values()))) for value in parameter_cases.values())\n",
    "    if not all_same_length:\n",
    "        raise ValueError(f\"All parameter value lists must be the same length for prescribed_cases!\")\n",
    "    \n",
    "    # convert to pandas dataframe\n",
    "    dfout = pd.DataFrame(parameter_cases)\n",
    "\n",
    "    # return result\n",
    "    return dfout\n",
    "\n",
    "# --- one at a time\n",
    "def one_at_a_time_sensitivity(\n",
    "        parameter_values: dict,\n",
    "        default_str: str = \"**default**\",\n",
    ")-> pd.DataFrame:\n",
    "    '''\n",
    "    Create pandas dataframe where each row is a test of a single value from a \n",
    "    single parameter, setting all else to default.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameter_cases : dict\n",
    "        dictionary with keys equal to default_dicts.py parameters \n",
    "        (must be numeric!) and values are values to test. Each \n",
    "        parameter value array must be the same length. \n",
    "    default_str : str\n",
    "        name to use if the value for the default dictionary should be used.\n",
    "        CAUTION: this might be hard-coded in the helper_functions.py to \n",
    "        expect a certain value! Only change if you know what you're doing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame \n",
    "        dataframe where each column is a parameter and each row is a sample\n",
    "    '''\n",
    "    # initialize an empty row\n",
    "    rows = []\n",
    "    # loop through each key and value in the parameter dict\n",
    "    for key, values in parameter_values.items():\n",
    "        for val in values:\n",
    "            # set all rows to default\n",
    "            row = {col: default_str for col in parameter_values.keys()}\n",
    "            row[key] = val # over-write the default value with the given parameter value\n",
    "            rows.append(row) \n",
    "    # return the dataframe\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# --- function to add constant values to the dict\n",
    "def add_constant_parameters(\n",
    "        df_batch: pd.DataFrame,\n",
    "        constant_dict: dict,\n",
    ")->pd.DataFrame:\n",
    "    '''\n",
    "    Take in the existing batch dataframe and add the constant parameter \n",
    "    values. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_batch : pd.DataFrame\n",
    "        the pandas dataframe that is output from one of the other sample \n",
    "        functions (latin_hypercube_sampler, all_combinations_sampler,\n",
    "        prescribed_cases).\n",
    "    constant_dict : dict\n",
    "        dictionary where keys are parameter names and each has a single \n",
    "        value that is held constant for all rows. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        the final batch .csv that gets saved\n",
    "    '''\n",
    "    # check that all dicts have only one value\n",
    "    all_len_1 = all((isinstance(value, (list, tuple)) and len(value) == 1) or not isinstance(value, (list, tuple)) for value in constant_dict.values())\n",
    "    if not all_len_1:\n",
    "        warnings.warn(\"Expected all dict parameters to have one value but at least one parameter has more. This may lead to unintended results.\", UserWarning)\n",
    "\n",
    "    # constant DataFrames\n",
    "    df2 = pd.DataFrame([constant_dict])\n",
    "\n",
    "    # Create a dummy key for cross join\n",
    "    df_batch['key'] = 1\n",
    "    df2['key'] = 1\n",
    "\n",
    "    # Merge the DataFrames on the dummy key\n",
    "    combined_df = pd.merge(df_batch, df2, on='key').drop('key', axis=1)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# --- add experiment name for the one_at_a_time_sensitivity case\n",
    "def add_exp_name_one_at_a_time(df, default_str=\"**default**\"):\n",
    "    '''\n",
    "    Add experiment names to the one_at_a_time output with the pattern\n",
    "    <parameter_name><counter>. For example, if the parameter that is not\n",
    "    default is \"max_dep\" and it's the first one in the df, the name will \n",
    "    be max_dep1. \n",
    "\n",
    "    Note, the code identifies which column's value is NOT == the default\n",
    "    string. If there is more than one, it takes the first column name. \n",
    "    '''\n",
    "    exp_names = []\n",
    "    counters = {col: 0 for col in df.columns if col != \"exp_name\"}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        for col in counters:\n",
    "            if row[col] != default_str:\n",
    "                counters[col] += 1\n",
    "                exp_names.append(f\"{col}{counters[col]}\")\n",
    "                break\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"casename\"] = exp_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datafile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+FLDS_lowTopo_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+FSDS_lowTopo_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+PRECT_lowTopo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+PS_lowTopo_50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+QFLX_lowTopo_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+RELHUM_lowTop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+TREFHT_lowTop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+U10_lowTopo_5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            datafile\n",
       "0  sensitivityRun_modernTopo_280ppm+FLDS_lowTopo_...\n",
       "1  sensitivityRun_modernTopo_280ppm+FSDS_lowTopo_...\n",
       "2  sensitivityRun_modernTopo_280ppm+PRECT_lowTopo...\n",
       "3  sensitivityRun_modernTopo_280ppm+PS_lowTopo_50...\n",
       "4  sensitivityRun_modernTopo_280ppm+QFLX_lowTopo_...\n",
       "5  sensitivityRun_modernTopo_280ppm+RELHUM_lowTop...\n",
       "6  sensitivityRun_modernTopo_280ppm+TREFHT_lowTop...\n",
       "7  sensitivityRun_modernTopo_280ppm+U10_lowTopo_5..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- create the pandas df\n",
    "dfout1 = one_at_a_time_sensitivity(parameter_clim_inputs)\n",
    "dfout1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add constant values\n",
    "constant_dict = {\n",
    "    # --- THE ONLY TWO REQUIRED COLUMNS ---\n",
    "    # [UPDATE TO PATH ON YOUR MACHINE]\n",
    "    \"default_dict_path\": \"/Users/tylerkukla/Documents/GitHub/PRYSM/psm/lake_v2/defaults\",\n",
    "    \"dict_name\": \"defaults_CP\",\n",
    "    # -------------------------------------\n",
    "    # \n",
    "    # other constants\n",
    "    # \"datafile\": \"CP_SLIM_modernTopo_280ppm_input.txt\",\n",
    "    \"outdir\": \"/Users/tylerkukla/Documents/GitHub/PRYSM/psm/lake_v2\",\n",
    "}\n",
    "\n",
    "# --- add to the dataframe\n",
    "df = dfout1.copy()\n",
    "\n",
    "# add the constants\n",
    "dfout2 = add_constant_parameters(df, constant_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casename</th>\n",
       "      <th>datafile</th>\n",
       "      <th>default_dict_path</th>\n",
       "      <th>dict_name</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datafile1</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+FLDS_lowTopo_...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datafile2</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+FSDS_lowTopo_...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datafile3</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+PRECT_lowTopo...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datafile4</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+PS_lowTopo_50...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datafile5</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+QFLX_lowTopo_...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datafile6</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+RELHUM_lowTop...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datafile7</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+TREFHT_lowTop...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datafile8</td>\n",
       "      <td>sensitivityRun_modernTopo_280ppm+U10_lowTopo_5...</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "      <td>defaults_CP</td>\n",
       "      <td>/Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    casename                                           datafile  \\\n",
       "0  datafile1  sensitivityRun_modernTopo_280ppm+FLDS_lowTopo_...   \n",
       "1  datafile2  sensitivityRun_modernTopo_280ppm+FSDS_lowTopo_...   \n",
       "2  datafile3  sensitivityRun_modernTopo_280ppm+PRECT_lowTopo...   \n",
       "3  datafile4  sensitivityRun_modernTopo_280ppm+PS_lowTopo_50...   \n",
       "4  datafile5  sensitivityRun_modernTopo_280ppm+QFLX_lowTopo_...   \n",
       "5  datafile6  sensitivityRun_modernTopo_280ppm+RELHUM_lowTop...   \n",
       "6  datafile7  sensitivityRun_modernTopo_280ppm+TREFHT_lowTop...   \n",
       "7  datafile8  sensitivityRun_modernTopo_280ppm+U10_lowTopo_5...   \n",
       "\n",
       "                                   default_dict_path    dict_name  \\\n",
       "0  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "1  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "2  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "3  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "4  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "5  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "6  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "7  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  defaults_CP   \n",
       "\n",
       "                                              outdir  \n",
       "0  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "1  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "2  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "3  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "4  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "5  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "6  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  \n",
       "7  /Users/tylerkukla/Documents/GitHub/PRYSM/psm/l...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- add unique name for each experiment\n",
    "dfout3 = add_exp_name_one_at_a_time(dfout2)\n",
    "# move 'casename' to the first position\n",
    "dfout4 = dfout3[['casename'] + [col for col in dfout3.columns if col != 'casename']]\n",
    "dfout4\n",
    "\n",
    "# (scratch)...\n",
    "# casename_root = \"sensitivity_one_at_a_time\"\n",
    "# dfout['casename'] = casename_root + \"_\" + (df.index + 1).astype(str)\n",
    "# # move 'casename' to the first position\n",
    "# dfout = dfout[['casename'] + [col for col in dfout.columns if col != 'casename']]\n",
    "# dfout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch file to /Users/tylerkukla/Documents/GitHub/PRYSM/psm/lake_v2/batch_inputs/batch_CP_sensitivity_climvars.csv\n"
     ]
    }
   ],
   "source": [
    "# --- save the result\n",
    "if SAVE_ON:\n",
    "    savefile = os.path.join(savehere, savename)\n",
    "    dfout4.to_csv(savefile, index=False)\n",
    "    print(f\"Saved batch file to {savefile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
